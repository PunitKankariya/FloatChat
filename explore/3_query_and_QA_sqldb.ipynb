{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/use_cases/sql/quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test the sqldb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from pyprojroot import here\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connecting to the sqldb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = str(here(\"data\")) + \"/csv_xlsx_sqldb.db\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.utilities.sql_database.SQLDatabase at 0x1fe002733d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['ocean_2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[('Paradip Coast', 2628.04, 15.98, 31.67, 359135.72, 7.49, 1.085, 'Medium', 32.03698004), ('Haldia Coast', 6655.49, 1.55, 31.68, 754228.57, 5.2, 1.316, 'Low', 54.46806663), ('Daman Coast', 5126.64, 10.1, 30.37, 604248.38, 2.95, 1.387, 'Low', 51.02472877), ('Kochi Coast', 4194.62, 4.03, 37.36, 512817.22, 6.18, 1.42, 'Low', 37.09633583), ('Kochi Coast', 1100.57, 1.9, 36.64, 209290.92, 6.76, 0.543, 'High', 34.86585202)]\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the connection to the vectordb\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM ocean_2 LIMIT 5;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test the access to the environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables are loaded: True\n",
      "test by reading a variable: AIzaSyCIjJcdvtJQulHXlLPLxSqcBXkOcv-IR9Q\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "print(\"Environment variables are loaded:\", load_dotenv())\n",
    "print(\"test by reading a variable:\", os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test your GPT(GEMINI) model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure the API key\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# Create the model\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Create the conversation with system instruction and user message\n",
    "# Note: Gemini handles system instructions differently - you can set it during model creation\n",
    "model_with_system = genai.GenerativeModel(\n",
    "    'gemini-1.5-flash',\n",
    "    system_instruction=\"You are a helpful assistant\"\n",
    ")\n",
    "\n",
    "# Generate response\n",
    "response = model_with_system.generate_content(\"hello\")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. SQL query chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Load the Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",  # or any other supported Gemini model\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many id are there\n",
      "SQLQuery: SELECT COUNT(*) FROM ocean_2;\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "\n",
    "chain = create_sql_query_chain(llm, db)\n",
    "response = chain.invoke({\"question\": \"How many id are there\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the query to make sure itâ€™s valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(19,)]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#db.run(response)\n",
    "# If your response contains both question and SQL, extract just the SQL part\n",
    "sql_query = response.split(\"SQLQuery: \")[1] if \"SQLQuery: \" in response else response\n",
    "db.run(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a SQLite expert. Given an input question, first create a syntactically correct SQLite query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use date('now') function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chain.get_prompts()[0].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Add QuerySQLDataBaseTool to the chain**\n",
    "Execute SQL query\n",
    "\n",
    "**This is the most dangerous part of creating a SQL chain.** Consider carefully if it is OK to run automated queries over your data. Minimize the database connection permissions as much as possible. Consider adding a human approval step to you chains before query execution (see below).\n",
    "\n",
    "We can use the QuerySQLDatabaseTool to easily add query execution to our chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [(4,)]\n",
      "Question: How many id have temperature in between 1 to 5\n",
      "Raw LLM Response: 'Question: How many id have temperature in between 1 to 5\\nSQLQuery: SELECT COUNT(*) FROM ocean_2 WHERE \"Temperature\" BETWEEN 1 AND 5'\n",
      "Cleaned SQL: SELECT COUNT(*) FROM ocean_2 WHERE \"Temperature\" BETWEEN 1 AND 5\n",
      "Query Result: [(4,)]\n",
      "Robust Chain Result: [(4,)]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import re\n",
    "\n",
    "# Your existing setup\n",
    "write_query = create_sql_query_chain(llm, db)\n",
    "execute_query = QuerySQLDatabaseTool(db=db)\n",
    "\n",
    "# Function to clean the SQL query\n",
    "def clean_sql_query(query_response):\n",
    "    \"\"\"\n",
    "    Extract clean SQL query from LLM response that may contain\n",
    "    formatted text like 'Question: ... SQLQuery: ...'\n",
    "    \"\"\"\n",
    "    # If the response contains \"SQLQuery:\", extract everything after it\n",
    "    if \"SQLQuery:\" in query_response:\n",
    "        sql_part = query_response.split(\"SQLQuery:\")[1].strip()\n",
    "        # Remove any trailing text after the first SQL statement\n",
    "        sql_lines = sql_part.split('\\n')\n",
    "        return sql_lines[0].strip()\n",
    "    \n",
    "    # If response contains \"Question:\", remove everything before \"SELECT\"\n",
    "    if \"Question:\" in query_response:\n",
    "        # Use regex to find the SELECT statement\n",
    "        match = re.search(r'(SELECT.*?)(?:\\n|$)', query_response, re.IGNORECASE | re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    \n",
    "    # Otherwise, assume it's already clean SQL\n",
    "    return query_response.strip()\n",
    "\n",
    "# Create a cleaning step\n",
    "sql_cleaner = RunnableLambda(clean_sql_query)\n",
    "\n",
    "# Build the fixed chain\n",
    "chain = write_query | sql_cleaner | execute_query\n",
    "\n",
    "# Test the chain\n",
    "try:\n",
    "    result = chain.invoke({\"question\": \"How many id have temperature in between 1 to 5\"})\n",
    "    print(f\"Result: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Alternative approach: Step-by-step execution for debugging\n",
    "def debug_chain_execution(question):\n",
    "    \"\"\"Execute chain step by step for debugging\"\"\"\n",
    "    print(f\"Question: {question}\")\n",
    "    \n",
    "    # Step 1: Generate SQL\n",
    "    raw_sql = write_query.invoke({\"question\": question})\n",
    "    print(f\"Raw LLM Response: {repr(raw_sql)}\")\n",
    "    \n",
    "    # Step 2: Clean SQL\n",
    "    clean_sql = clean_sql_query(raw_sql)\n",
    "    print(f\"Cleaned SQL: {clean_sql}\")\n",
    "    \n",
    "    # Step 3: Execute SQL\n",
    "    try:\n",
    "        result = execute_query.run(clean_sql)\n",
    "        print(f\"Query Result: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Execution Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Debug execution\n",
    "debug_result = debug_chain_execution(\"How many id have temperature in between 1 to 5\")\n",
    "\n",
    "# More robust chain with error handling\n",
    "def create_robust_sql_chain(llm, db):\n",
    "    \"\"\"Create a more robust SQL chain with better error handling\"\"\"\n",
    "    \n",
    "    def safe_sql_execution(sql_query):\n",
    "        \"\"\"Safely execute SQL with cleaning and error handling\"\"\"\n",
    "        try:\n",
    "            # Clean the query\n",
    "            clean_query = clean_sql_query(sql_query)\n",
    "            \n",
    "            # Validate it looks like SQL\n",
    "            if not any(keyword in clean_query.upper() for keyword in ['SELECT', 'INSERT', 'UPDATE', 'DELETE']):\n",
    "                return f\"Error: Generated text doesn't appear to be valid SQL: {clean_query}\"\n",
    "            \n",
    "            # Execute the query\n",
    "            tool = QuerySQLDatabaseTool(db=db)\n",
    "            return tool.run(clean_query)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error executing SQL: {str(e)}\"\n",
    "    \n",
    "    # Create the robust chain\n",
    "    robust_chain = (\n",
    "        create_sql_query_chain(llm, db) \n",
    "        | RunnableLambda(safe_sql_execution)\n",
    "    )\n",
    "    \n",
    "    return robust_chain\n",
    "\n",
    "# Use the robust chain\n",
    "robust_chain = create_robust_sql_chain(llm, db)\n",
    "result = robust_chain.invoke({\"question\": \"How many id have temperature in between 1 to 5\"})\n",
    "print(f\"Robust Chain Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Answer the question in a user friendly manner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The SQL query failed to execute due to a syntax error.  The error message indicates a problem with the way the query is formatted, specifically mentioning a syntax error near \"Question:\".  The query itself (`SELECT COUNT(*) FROM ocean_2 WHERE \"Temperature\" BETWEEN 1 AND 5`) appears correct *except* for the fact that it\\'s preceded by text that\\'s not valid SQL.  The error is not related to the data or the logic of counting IDs with temperatures between 1 and 5.\\n\\nTo answer the user\\'s question, the erroneous \"Question:\" needs to be removed from the SQL query before it can be run.  Once that\\'s fixed, the query will return the number of IDs with temperatures between 1 and 5 (inclusive) from the `ocean_2` table.  Without a corrected execution and result, we cannot provide a numerical answer.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "answer = answer_prompt | llm | StrOutputParser()\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=write_query).assign(\n",
    "        result=itemgetter(\"query\") | execute_query\n",
    "    )\n",
    "    | answer\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": \"How many id have temperature in between 1 to 5\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Agents**\n",
    "\n",
    "Agent which provides a more flexible way of interacting with SQL databases. The main advantages of using the SQL Agent are:\n",
    "\n",
    "- It can answer questions based on the databasesâ€™ schema as well as on the databasesâ€™ content (like describing a specific table).\n",
    "- It can recover from errors by running a generated query, catching the traceback and regenerating it correctly.\n",
    "- It can answer questions that require multiple dependent queries.\n",
    "- It will save tokens by only considering the schema from relevant tables.\n",
    "\n",
    "To initialize the agent, we use create_sql_agent function. This agent contains the SQLDatabaseToolkit which contains tools to:\n",
    "\n",
    "- Create and execute queries\n",
    "- Check query syntax\n",
    "- Retrieve table descriptions\n",
    "- â€¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm, \n",
    "    db=db, \n",
    "    agent_type=\"tool-calling\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mocean_2\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'ocean_2'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE ocean_2 (\n",
      "\t\"Location\" TEXT, \n",
      "\t\"Depth\" FLOAT, \n",
      "\t\"Temperature\" FLOAT, \n",
      "\t\"Salinity\" FLOAT, \n",
      "\t\"Pressure\" FLOAT, \n",
      "\t\"Dissolved Oxygen\" FLOAT, \n",
      "\t\"Sea Level\" FLOAT, \n",
      "\t\"Tsunami Risk Level\" TEXT, \n",
      "\t\"Conductivity\" FLOAT\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from ocean_2 table:\n",
      "Location\tDepth\tTemperature\tSalinity\tPressure\tDissolved Oxygen\tSea Level\tTsunami Risk Level\tConductivity\n",
      "Paradip Coast\t2628.04\t15.98\t31.67\t359135.72\t7.49\t1.085\tMedium\t32.03698004\n",
      "Haldia Coast\t6655.49\t1.55\t31.68\t754228.57\t5.2\t1.316\tLow\t54.46806663\n",
      "Daman Coast\t5126.64\t10.1\t30.37\t604248.38\t2.95\t1.387\tLow\t51.02472877\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': 'SELECT COUNT(*) FROM ocean_2 WHERE Temperature BETWEEN 1 AND 5'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[(4,)]\u001b[0m\u001b[32;1m\u001b[1;3mThere are 4 ids with temperature between 1 and 5.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How many id have temperature in between 1 to 5 ?',\n",
       " 'output': 'There are 4 ids with temperature between 1 and 5.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"How many id have temperature in between 1 to 5 ?\"\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
